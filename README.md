# Next
*Last updated: October 6th, 2020*

**So, you started learning Python. Now what?**

The [Python for Journalists MOOC](https://datajournalism.com/watch/python-for-journalists) I got to create for [Datajournalism.com](https://datajournalism.com) has found its way to journalists eager to learn Python. Which off course is great. But when you're done with that course, what's next?

In this living repository I'll collect Jupyter Notebooks that contain code that I actually wrote and used in the newsroom. To make sure it will help you learn Python, I'll add comments, links and tips to my code. If I do this right, my code should become a workbook in which you can practice. :)

Some Notebooks will be in Dutch, others will be in English. An overview of all of them can be found here:


| Notebook| Content | Language |
| :------------- |:-------------|:-----:|
| [201006 two step scraper notebookcheck.ipynb](https://github.com/winnydejong/next/blob/master/201006%20two%20step%20scraper%20notebookcheck.ipynb) | My friend A. wanted to scrape notebookcheck.com, to get some specs on smartphones. Figured you might want to hop along on this quirky scrape-journey. Shows how to scrape non-tabular data, uses regular expressions. | EN |
| [200923 Webscraping with Python - Dataharvest 2020.ipynb](https://github.com/winnydejong/next/blob/master/200923%20Webscraping%20with%20Python%20-%20Dataharvest%202020%20%5Bcomplete%5D.ipynb) | This Notebook contains a scraper to collect all [the program](dataharvesteijc2020.sched.com/) of the 2020 [DataHarvest+ European Investigative Journalism Conference](https://dataharvest.eu/). It was created for a DataHarvest+ [session on Python](https://dataharvesteijc2020.sched.com/event/dkjh/data-analysis-with-pandas-on-jupyter-3?iframe=no), taught together with the [wonderful Adriana Homolova](https://github.com/zufanka). FYI: There also exists an [empty version of this notebook](https://github.com/winnydejong/next/blob/master/200923%20Webscraping%20with%20Python%20-%20Dataharvest%202020%20%5Bempty%5D.ipynb). (Oh, and a final note, you'll find all [material used in the Python sessions of DataHarvest+ 2020](https://github.com/zufanka/DataAnalysisPython_DataHarvest2020) taught by Adriana and yours truly here.) | EN |
| [200923 Scraper info Dutch municipalities.ipynb](https://github.com/winnydejong/next/blob/master/200923%20Scraper%20info%20Dutch%20municipalities.ipynb) | This Notebook contains a scraper to collect all contactinfo; list of political parties and the number of seats they have; and names, parties and function of every single city councillor for every county (gemeente) in the Netherlands from [almanak.overheid.nl](https://almanak.overheid.nl/). Also written for the Dataharvest+ EIJC 2020. :) | EN |
| [190722 Almanak Gemeenten Scraper + Toelichting.ipynb](https://github.com/winnydejong/next/blob/master/190722%20Almanak%20Gemeenten%20Scraper%20%2B%20Toelichting.ipynb) | This Notebook contains a scraper to collect all contactinfo for every county (gemeente) in the Netherlands from [almanak.overheid.nl](https://almanak.overheid.nl/). Builds upon the [4th module of the Python for Journalists MOOC](https://datajournalism.com/watch/python-for-journalists). | NL  |
| [190723 Almanak Provincies Scraper + Toelichting.ipynb](https://github.com/winnydejong/next/blob/master/190723%20Almanak%20Provincies%20Scraper%20%2B%20Toelichting.ipynb) | This Notebook contains a scraper to collect all contactinfo for every province (provincie) in the Netherlands from [almanak.overheid.nl](https://almanak.overheid.nl/). Builds both upon the [4th module of the Python for Journalists MOOC](https://datajournalism.com/watch/python-for-journalists) and the county scraper [190722 Almanak Gemeenten Scraper + Toelichting.ipynb](https://github.com/winnydejong/next/blob/master/190722%20Almanak%20Gemeenten%20Scraper%20%2B%20Toelichting.ipynb). | NL |
| [Search Script Scrape Notebook.ipynb](https://github.com/winnydejong/next/blob/master/Search%20Script%20Scrape%20Notebook.ipynb) | This notebook contains answers to some of the [101 webscraping and research tasks](https://github.com/stanfordjournalism/search-script-scrape) that were an exercise part of the Stanford Computational Journalism Lab. | EN  | 
